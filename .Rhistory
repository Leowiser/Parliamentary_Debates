mutate(sent = pos-neg)
df_clean <- cbind(df_clean, sentiment_speech[,-1])
colnames(df_clean)
head(df_clean)
df_clean %>%
group_by(debate_title) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = debate_title)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
df_result = read.csv('Parliamentary_Debates.csv', row.names = 1)
# Delete all the duplicates
df_clean <- distinct(df_result)
n_distinct(df_clean$speech_id)
n_distinct(df_clean$speech_content)
poswords = "https://cssbook.net/d/positive.txt"
negwords = "https://cssbook.net/d/negative.txt"
pos = scan(poswords, what = "list")
neg = scan(negwords, what = "list")
sentimentdict = dictionary(list(pos = pos, neg = neg))
# Need to rename the column of the speeches to 'text' because the corpus() function from the following code needs that naming convention
names(df_clean)[names(df_clean) == "speech_content"] <- "text"
# Match and calculate the sentiments
sentiment_speech = df_clean %>%
corpus() %>%
tokens() %>%
dfm() %>%
dfm_lookup(sentimentdict) %>%
convert(to = "data.frame") %>%
mutate(sent = pos-neg)
df_clean <- cbind(df_clean, sentiment_speech[,-1])
colnames(df_clean)
head(df_clean)
df_clean %>%
group_by(debate_title) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = debate_title)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
poswords = "https://cssbook.net/d/positive.txt"
negwords = "https://cssbook.net/d/negative.txt"
pos = scan(poswords, what = "list")
neg = scan(negwords, what = "list")
sentimentdict = dictionary(list(pos = pos, neg = neg))
# Need to rename the column of the speeches to 'text' because the corpus() function from the following code needs that naming convention
names(df_clean)[names(df_clean) == "speech_content"] <- "text"
# Match and calculate the sentiments
sentiment_speech = df_clean %>%
corpus() %>%
tokens() %>%
dfm() %>%
dfm_lookup(sentimentdict) %>%
convert(to = "data.frame") %>%
mutate(sent = pos-neg)
df_clean <- cbind(df_clean, sentiment_speech[,-1])
df_clean %>%
group_by(debate_title) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = debate_title)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
df_result = read.csv('Parliamentary_Debates.csv', row.names = 1)
# Delete all the duplicates
df_clean <- distinct(df_result)
n_distinct(df_clean$speech_id)
n_distinct(df_clean$speech_content)
poswords = "https://cssbook.net/d/positive.txt"
negwords = "https://cssbook.net/d/negative.txt"
pos = scan(poswords, what = "list")
neg = scan(negwords, what = "list")
sentimentdict = dictionary(list(pos = pos, neg = neg))
# Need to rename the column of the speeches to 'text' because the corpus() function from the following code needs that naming convention
names(df_clean)[names(df_clean) == "speech_content"] <- "text"
# Match and calculate the sentiments
sentiment_speech = df_clean %>%
corpus() %>%
tokens() %>%
dfm() %>%
dfm_lookup(sentimentdict) %>%
convert(to = "data.frame") %>%
mutate(sent = pos-neg)
df_clean <- cbind(df_clean, sentiment_speech[,-1])
df_clean %>%
group_by(debate_title) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = debate_title)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
#### US State of the union speeches ####
url = "https://cssbook.net/d/sotu.csv"
sotu = read_csv(url)
head(sotu)
colnames(sotu)
class(sotu)
library(tidyverse)
sentiment_speech = sotu %>%
corpus() %>%
tokens() %>%
dfm() %>%
dfm_lookup(sentimentdict) %>%
convert(to = "data.frame") %>%
mutate(sent = pos-neg)
names(df_clean)[names(df_clean) == "speech_content"] <- "text"
sentiment_speech <- cbind(sotu, sentiment_speech[,-1])
colnames(sentiment_speech)
head(sentiment_speech)
sentiment_speech %>%
group_by(debate_title) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = debate_title)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
sentiment_speech %>%
group_by(President) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = President)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
ggplot(sentiment_speech, aes(x = Date, y = sent)) +
geom_line(color='steelblue') +
xlab("Year") +
theme_minimal()
View(sentiment_speech)
View(df_clean)
View(df_clean)
View(df_clean)
View(sentiment_speech)
df_result = read.csv('Parliamentary_Debates.csv', row.names = 1)
# Delete all the duplicates
df_clean <- distinct(df_result)
n_distinct(df_clean$speech_id)
n_distinct(df_clean$speech_content)
# Format the debate_date column so that it contains dates not character strings
df_clean$debate_date <- as.Date(df_clean$debate_date, format = "%d %B %Y")
df_result = read.csv('Parliamentary_Debates.csv', row.names = 1)
# Delete all the duplicates
df_clean <- distinct(df_result)
n_distinct(df_clean$speech_id)
n_distinct(df_clean$speech_content)
# Format the debate_date column so that it contains dates not character strings
# df_clean$debate_date <- as.Date(df_clean$debate_date, format = "%d %B %Y")
df_clean$debate_date
as.Date(df_clean$debate_date, format = "%d %B %Y")
as.Date(df_clean$debate_date, format = "%dd %mmmm %Yyyy")
unique(df_clean$debate_date)
df_clean$debate_date <- trimws(df_clean$debate_date)  # Remove leading/trailing spaces
df_clean$debate_date <- tolower(df_clean$debate_date) # Convert to lowercase
df_clean$debate_date <- gsub("(^|\\s)([a-z])", "\\1\\U\\2", df_clean$debate_date, perl=TRUE)  # Capitalize the first letter of each word
unique(df_clean$debate_date)
df_clean$debate_date <- as.Date(df_clean$debate_date, format = "%d %B %Y")
# Check the result
head(df_clean)
df_result = read.csv('Parliamentary_Debates.csv', row.names = 1)
# Delete all the duplicates
df_clean <- distinct(df_result)
n_distinct(df_clean$speech_id)
n_distinct(df_clean$speech_content)
# Format the debate_date column so that it contains dates not character strings
# df_clean$debate_date <- as.Date(df_clean$debate_date, format = "%d %B %Y")
library(lubridate)
df_clean$debate_date <- dmy(df_clean$debate_date)
library("tidyverse")
library("httr")
library("jsonlite")
library("rvest")
library("xml2")
library("glue")
library("data.table")
library("rvest")
library("xml2")
library("glue")
library("data.table")
library("quanteda")
library("topicmodels")
library(readxl)
library(tm)
library(tidytext)
library(dplyr)
library(lubridate)    # for date conversion in data cleaning
df_result = read.csv('Parliamentary_Debates.csv', row.names = 1)
# Delete all the duplicates
df_clean <- distinct(df_result)
n_distinct(df_clean$speech_id)
n_distinct(df_clean$speech_content)
# Format the debate_date column so that it contains dates not character strings
df_clean$debate_date <- dmy(df_clean$debate_date)
ggplot(df_clean, aes(x = debate_date, y = sent)) +
geom_line(color='steelblue') +
xlab("Year") +
theme_minimal()
poswords = "https://cssbook.net/d/positive.txt"
negwords = "https://cssbook.net/d/negative.txt"
pos = scan(poswords, what = "list")
neg = scan(negwords, what = "list")
sentimentdict = dictionary(list(pos = pos, neg = neg))
# Need to rename the column of the speeches to 'text' because the corpus() function from the following code needs that naming convention
names(df_clean)[names(df_clean) == "speech_content"] <- "text"
# Match and calculate the sentiments
sentiment_speech = df_clean %>%
corpus() %>%
tokens() %>%
dfm() %>%
dfm_lookup(sentimentdict) %>%
convert(to = "data.frame") %>%
mutate(sent = pos-neg)
df_clean <- cbind(df_clean, sentiment_speech[,-1])
df_clean %>%
group_by(debate_title) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = debate_title)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
ggplot(df_clean, aes(x = debate_date, y = sent)) +
geom_line(color='steelblue') +
xlab("Year") +
theme_minimal()
url = "https://cssbook.net/d/sotu.csv"
sotu = read_csv(url)
head(sotu)
colnames(sotu)
class(sotu)
library(tidyverse)
sentiment_speech = sotu %>%
corpus() %>%
tokens() %>%
dfm() %>%
dfm_lookup(sentimentdict) %>%
convert(to = "data.frame") %>%
mutate(sent = pos-neg)
names(df_clean)[names(df_clean) == "speech_content"] <- "text"
sentiment_speech <- cbind(sotu, sentiment_speech[,-1])
colnames(sentiment_speech)
head(sentiment_speech)
sentiment_speech %>%
group_by(President) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = President)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
ggplot(sentiment_speech, aes(x = Date, y = sent)) +
geom_line(color='steelblue') +
xlab("Year") +
theme_minimal()
View(sentiment_speech)
library("tidyverse")
library("httr")
library("jsonlite")
library("rvest")
library("xml2")
library("glue")
library("data.table")
library("rvest")
library("xml2")
library("glue")
library("data.table")
library("quanteda")
library("topicmodels")
library(readxl)
library(tm)
library(tidytext)
library(dplyr)
library(lubridate)    # for date conversion in data cleaning
df_result = read.csv('Parliamentary_Debates.csv', row.names = 1)
# Delete all the duplicates
df_clean <- distinct(df_result)
n_distinct(df_clean$speech_id)
n_distinct(df_clean$speech_content)
# Format the debate_date column so that it contains dates not character strings
df_clean$debate_date <- dmy(df_clean$debate_date)
View(df_clean)
View(df_clean)
poswords = "https://cssbook.net/d/positive.txt"
negwords = "https://cssbook.net/d/negative.txt"
pos = scan(poswords, what = "list")
neg = scan(negwords, what = "list")
sentimentdict = dictionary(list(pos = pos, neg = neg))
# Need to rename the column of the speeches to 'text' because the corpus() function from the following code needs that naming convention
names(df_clean)[names(df_clean) == "speech_content"] <- "text"
# Match and calculate the sentiments
sentiment_speech = df_clean %>%
corpus() %>%
tokens() %>%
dfm() %>%
dfm_lookup(sentimentdict) %>%
convert(to = "data.frame") %>%
mutate(sent = pos-neg)
df_clean <- cbind(df_clean, sentiment_speech[,-1])
df_clean %>%
group_by(debate_title) %>%
summarise(mean_sent = mean(sent)) %>%
ggplot(aes(x = mean_sent, y = debate_title)) +
geom_bar(stat = "identity", fill = 'steelblue') +
theme_minimal()
# This is probably incorrect, would need grouping like before imo
ggplot(df_clean, aes(x = debate_date, y = sent)) +
geom_line(color='steelblue') +
xlab("Year") +
theme_minimal()
View(df_clean)
View(df_clean)
unique(df_clean$debate_date)
unique(df_result$debate_date)
View(df_result)
df_result$debate_date <- dmy(df_result$debate_date)
View(df_result)
View(df_result)
View(df_result)
View(df_result)
View(df_clean)
View(df_clean)
set.seed(123)  # For reproducibility
sampled_speeches <- df_clean %>%
sample_n(20)  # Randomly sample 20 speeches
# Tokenize the speeches
tokenized_speeches <- sampled_speeches %>% View()
# Tokenize the speeches
tokenized_speeches <- sampled_speeches %>%
unnest_tokens(word, text) %>% View()
# Tokenize the speeches
tokenized_speeches <- sampled_speeches %>%
unnest_tokens(word, text)
View(tokenized_speeches)
# Classify each word as positive, negative, or neutral
validation_df <- tokenized_speeches %>%
mutate(sentiment = case_when(
word %in% pos ~ "positive",
word %in% neg ~ "negative",
TRUE ~ "neutral"
))
View(validation_df)
View(df_clean)
# Display the validation dataframe
validation_df <- validation_df %>%
select(speech_id, word, sentiment)
# Print the validation dataframe
print(validation_df)
# Summarize counts of positive, negative, and neutral words by speech
validation_summary <- validation_df %>%
group_by(speech_id) %>%
summarize(
positive = sum(sentiment == "positive"),
negative = sum(sentiment == "negative"),
neutral = sum(sentiment == "neutral")
)
# Print the summary
print(validation_summary)
# Classify each word as positive, negative, or neutral
validation_df <- tokenized_speeches %>%
mutate(sentiment = case_when(
word %in% pos ~ "positive",
word %in% neg ~ "negative"
))
"proud" %in% pos
View(validation_df)
View(tokenized_speeches)
"congratulate" %in% pos
pos_words <- pos
# Classify each word as positive, negative, or neutral
validation_df <- tokenized_speeches %>%
mutate(sentiment = case_when(
word %in% pos_words ~ "positive",
word %in% neg ~ "negative"
))
text = c("We learn incredibly cool stuff in this fantastic class", "Unfortunately, every fun class needs to end with a dreadful difficult paper exercise")
scores1 = text %>%
tokens() %>%
dfm() %>%
dfm_lookup(sentimentdict) %>%
convert(to = "data.frame") %>%
mutate(sent = pos-neg)
scores1
neat_text <-function(text){
temp <- tolower(text)
temp <- gsub("[[:punct:][:blank:]]+", " ", temp)
corp_temp <- corpus(temp)
toks <- tokens(corp_temp)
toks_nostop <- tokens_select(toks, pattern = stopwords("en"), selection = "remove")
}
text_new <- neat_text(text)
text_new <- as.list(text_new)
sentimentdict2 <- as.list(sentimentdict)
for (i in 1:length(text_new)) {
for (j in 1:length(sentimentdict2)) {
print(text_new[[i]])
print(text_new[[i]] %in% sentimentdict2[[j]])
}
}
set.seed(123)  # For reproducibility
sampled_speeches <- df_clean %>%
sample_n(20)  # Randomly sample 20 speeches
# Extract the text column for easier manipulation
texts <- sampled_speeches$text
neat_text <- function(text) {
temp <- tolower(text)
temp <- gsub("[[:punct:][:blank:]]+", " ", temp)
corp_temp <- corpus(temp)
toks <- tokens(corp_temp)
toks_nostop <- tokens_select(toks, pattern = stopwords("en"), selection = "remove")
return(toks_nostop)
}
texts_cleaned <- lapply(texts, neat_text)
texts_cleaned
# Convert tokens to a simple list format for easier manipulation
texts_cleaned_list <- lapply(texts_cleaned, as.list)
texts_cleaned_list
# Convert the sentiment dictionary to a list format
sentimentdict_list <- as.list(sentimentdict)
# Function to check sentiment for each word in the text
check_sentiment <- function(words, sentimentdict_list) {
word_sentiments <- sapply(words, function(word) {
if (word %in% sentimentdict_list$pos) {
return("positive")
} else if (word %in% sentimentdict_list$neg) {
return("negative")
} else {
return("neutral")
}
})
return(word_sentiments)
}
# Iterate over each text and print the words with their sentiment classification
for (i in 1:length(texts_cleaned_list)) {
cat("\nSpeech", i, ":\n")
words <- unlist(texts_cleaned_list[[i]])
sentiments <- check_sentiment(words, sentimentdict_list)
# Print each word with its sentiment
for (j in 1:length(words)) {
cat(words[j], ":", sentiments[j], "\n")
}
}
# Extract the text column for easier manipulation
texts <- sampled_speeches$text
neat_text <- function(text) {
temp <- tolower(text)
temp <- gsub("[[:punct:][:blank:]]+", " ", temp)
corp_temp <- corpus(temp)
toks <- tokens(corp_temp)
# toks_nostop <- tokens_select(toks, pattern = stopwords("en"), selection = "remove")
return(toks)
}
texts_cleaned <- lapply(texts, neat_text)
# Convert tokens to a simple list format for easier manipulation
texts_cleaned_list <- lapply(texts_cleaned, as.list)
texts_cleaned_list
# Convert the sentiment dictionary to a list format
sentimentdict_list <- as.list(sentimentdict)
# Function to check sentiment for each word in the text
check_sentiment <- function(words, sentimentdict_list) {
word_sentiments <- sapply(words, function(word) {
if (word %in% sentimentdict_list$pos) {
return("positive")
} else if (word %in% sentimentdict_list$neg) {
return("negative")
} else {
return("neutral")
}
})
return(word_sentiments)
}
# Iterate over each text and print the words with their sentiment classification
for (i in 1:length(texts_cleaned_list)) {
cat("\nSpeech", i, ":\n")
words <- unlist(texts_cleaned_list[[i]])
sentiments <- check_sentiment(words, sentimentdict_list)
# Print each word with its sentiment
for (j in 1:length(words)) {
cat(words[j], ":", sentiments[j], "\n")
}
}
sampled_speeches <- df_clean[1:20, ]
# Extract the text column for easier manipulation
texts <- sampled_speeches$text
neat_text <- function(text) {
temp <- tolower(text)
temp <- gsub("[[:punct:][:blank:]]+", " ", temp)
corp_temp <- corpus(temp)
toks <- tokens(corp_temp)
# toks_nostop <- tokens_select(toks, pattern = stopwords("en"), selection = "remove")
return(toks)
}
texts_cleaned <- lapply(texts, neat_text)
# Convert tokens to a simple list format for easier manipulation
texts_cleaned_list <- lapply(texts_cleaned, as.list)
# Convert the sentiment dictionary to a list format
sentimentdict_list <- as.list(sentimentdict)
texts_cleaned_list
# Convert the sentiment dictionary to a list format
sentimentdict_list <- as.list(sentimentdict)
# Function to check sentiment for each word in the text
check_sentiment <- function(words, sentimentdict_list) {
word_sentiments <- sapply(words, function(word) {
if (word %in% sentimentdict_list$pos) {
return("positive")
} else if (word %in% sentimentdict_list$neg) {
return("negative")
} else {
return("neutral")
}
})
return(word_sentiments)
}
# Iterate over each text and print the words with their sentiment classification
for (i in 1:length(texts_cleaned_list)) {
cat("\nSpeech", i, ":\n")
words <- unlist(texts_cleaned_list[[i]])
sentiments <- check_sentiment(words, sentimentdict_list)
# Print each word with its sentiment
for (j in 1:length(words)) {
cat(words[j], ":", sentiments[j], "\n")
}
}
View(df_clean)
